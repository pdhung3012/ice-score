{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617dc10d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b701c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy import stats\n",
    "from numpy import mean\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from numpy import nanmean\n",
    "\n",
    "def l_extend(l):\n",
    "    return [lll for ll in l for lll in ll]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b1866",
   "metadata": {},
   "source": [
    "# CoNaLa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac0c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conala_models_list = ['baseline', 'tranx-annot', 'best-tranx', 'best-tranx-rerank', 'codex']\n",
    "\n",
    "exp_metrics = [\"bleu\",\"codebleu\",\"chrf\",\"rougel\",\"meteor\",\"ruby\",\n",
    "               \"codebertscore_f1\",\"codebertscore_s_f1\",\n",
    "               \"codebertscore_f3\",\"codebertscore_s_f3\",\n",
    "               \"gpt35_nsnr\",\"gpt35_nswr\",\"gpt35_wsnr\",\"gpt35_wswr\"\n",
    "              ]\n",
    "real_name_metrics=[\"BLEU\",\"CodeBLEU\",\"chrF\",\"ROUGE-L\",\"METEOR\",\"RUBY\",\n",
    "                   \"CodeBERTSCORE-F1 (w/o S.)\",\"CodeBERTSCORE-F1 (w/ S.)\",\n",
    "                   \"CodeBERTSCORE-F3 (w/o S.)\",\"CodeBERTSCORE-F3 (w/ S.)\",\n",
    "                   \"GPT-3.5 (w/o R.)\",\"GPT-3.5 (w/ R.)\",\n",
    "                   \"GPT-3.5 (w/o R.) + 0-shot-CoT\",\"GPT-3.5 (w/ R.) + 0-shot-CoT\"\n",
    "                  ]\n",
    "def compute(data,metric,level=\"example\"):\n",
    "    refs,preds=[],[]\n",
    "    for d in data:\n",
    "        refs.append([d[f\"grade-{k}\"] for k in conala_models_list])\n",
    "        preds.append([d[f\"{metric}-{k}\"] for k in conala_models_list])\n",
    "    if level==\"example\":\n",
    "        return nanmean([stats.kendalltau(ref,pred).statistic for ref,pred in zip(refs,preds)]),\\\n",
    "                nanmean([stats.pearsonr(ref,pred).statistic for ref,pred in zip(refs,preds)]),\\\n",
    "                nanmean([stats.spearmanr(ref,pred).statistic for ref,pred in zip(refs,preds)])\n",
    "    else:\n",
    "        return stats.kendalltau(l_extend(refs),l_extend(preds)).statistic,\\\n",
    "            stats.pearsonr(l_extend(refs),l_extend(preds)).statistic,\\\n",
    "            stats.spearmanr(l_extend(refs),l_extend(preds)).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce001a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU\n",
      "\t\t .439 .522 .488\n",
      "CodeBLEU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/general_env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/mnt/d/general_env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4921: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t .292 .363 .331\n",
      "chrF\n",
      "\t\t .458 .570 .515\n",
      "ROUGE-L\n",
      "\t\t .447 .529 .499\n",
      "METEOR\n",
      "\t\t .410 .507 .462\n",
      "RUBY\n",
      "\t\t .331 .397 .371\n",
      "CodeBERTSCORE-F1 (w/o S.)\n",
      "\t\t .499 .595 .558\n",
      "CodeBERTSCORE-F1 (w/ S.)\n",
      "\t\t .500 .609 .556\n",
      "CodeBERTSCORE-F3 (w/o S.)\n",
      "\t\t .485 .587 .542\n",
      "CodeBERTSCORE-F3 (w/ S.)\n",
      "\t\t .505 .609 .563\n",
      "GPT-3.5 (w/o R.)\n",
      "\t\t .556 .613 .594\n",
      "GPT-3.5 (w/ R.)\n",
      "\t\t .554 .617 .591\n",
      "GPT-3.5 (w/o R.) + 0-shot-CoT\n",
      "\t\t .561 .628 .600\n",
      "GPT-3.5 (w/ R.) + 0-shot-CoT\n",
      "\t\t .571 .639 .607\n"
     ]
    }
   ],
   "source": [
    "# Example Level\n",
    "for m,rm in zip(exp_metrics,real_name_metrics):\n",
    "    print(rm)\n",
    "    kendalls,pearsons,spearmans=[],[],[]\n",
    "    with open(f\"data/conala/conala_grade.json\") as f:\n",
    "        data = json.load(f)\n",
    "    kendall,pearson,spearman = compute(data,m,level=\"example\")\n",
    "    kendalls.append(kendall)\n",
    "    pearsons.append(pearson)\n",
    "    spearmans.append(spearman)\n",
    "    print(\"\\t\\t\",\n",
    "          \"{:.3f}\".format(round(kendall,3))[1:],\n",
    "          \"{:.3f}\".format(round(pearson,3))[1:],\n",
    "          \"{:.3f}\".format(round(spearman,3))[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6deb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU\n",
      "\t\t .423 .572 .542\n",
      "CodeBLEU\n",
      "\t\t .259 .397 .339\n",
      "chrF\n",
      "\t\t .449 .592 .578\n",
      "ROUGE-L\n",
      "\t\t .432 .581 .552\n",
      "METEOR\n",
      "\t\t .415 .557 .534\n",
      "RUBY\n",
      "\t\t .339 .493 .439\n",
      "CodeBERTSCORE-F1 (w/o S.)\n",
      "\t\t .460 .579 .589\n",
      "CodeBERTSCORE-F1 (w/ S.)\n",
      "\t\t .464 .579 .595\n",
      "CodeBERTSCORE-F3 (w/o S.)\n",
      "\t\t .441 .556 .568\n",
      "CodeBERTSCORE-F3 (w/ S.)\n",
      "\t\t .437 .549 .564\n",
      "GPT-3.5 (w/o R.)\n",
      "\t\t .546 .649 .635\n",
      "GPT-3.5 (w/ R.)\n",
      "\t\t .539 .661 .630\n",
      "GPT-3.5 (w/o R.) + 0-shot-CoT\n",
      "\t\t .579 .703 .665\n",
      "GPT-3.5 (w/ R.) + 0-shot-CoT\n",
      "\t\t .583 .712 .667\n"
     ]
    }
   ],
   "source": [
    "# Corpus Level\n",
    "for m,rm in zip(exp_metrics,real_name_metrics):\n",
    "    print(rm)\n",
    "    kendalls,pearsons,spearmans=[],[],[]\n",
    "    with open(f\"data/conala/conala_grade.json\") as f:\n",
    "        data = json.load(f)\n",
    "    kendall,pearson,spearman = compute(data,m,level=\"corpus\")\n",
    "    kendalls.append(kendall)\n",
    "    pearsons.append(pearson)\n",
    "    spearmans.append(spearman)\n",
    "    print(\"\\t\\t\",\n",
    "          \"{:.3f}\".format(round(kendall,3))[1:],\n",
    "          \"{:.3f}\".format(round(pearson,3))[1:],\n",
    "          \"{:.3f}\".format(round(spearman,3))[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e66962",
   "metadata": {},
   "source": [
    "# HumanEval-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34e72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metrics = [\"bleu\",\"codebleu\",\"chrf\",\"rougel\",\"meteor\",\"ruby\",\"codebertscore\",\"gpt35\"]\n",
    "exp_metrics = [\"bleu\",\"codebleu\",\"chrf\",\"rougel\",\"meteor\",\"ruby\",\n",
    "               \"codebertscore_f1\",\"codebertscore_s_f1\",\n",
    "               \"codebertscore_f3\",\"codebertscore_s_f3\",\n",
    "               \"gpt35_nsnr\",\"gpt35_nswr\"\n",
    "              ]\n",
    "real_name_metrics=[\"BLEU\",\"CodeBLEU\",\"chrF\",\"ROUGE-L\",\"METEOR\",\"RUBY\",\n",
    "                   \"CodeBERTSCORE-F1 (w/o S.)\",\"CodeBERTSCORE-F1 (w/ S.)\",\n",
    "                   \"CodeBERTSCORE-F3 (w/o S.)\",\"CodeBERTSCORE-F3 (w/ S.)\",\n",
    "                   \"GPT-3.5 (w/o R.)\",\"GPT-3.5 (w/ R.)\"\n",
    "                  ]\n",
    "def compute(data,metric,level=\"example\"):\n",
    "    refs,preds=[],[]\n",
    "    for d in data:\n",
    "        ks=[k.replace(\"grade-\",\"\") for k in d.keys() if k.startswith(\"grade-\")]\n",
    "        refs.append([d[f\"grade-{k}\"][\"execution\"] for k in ks])\n",
    "        preds.append([d[f\"{metric}-{k}\"] for k in ks])\n",
    "    if level==\"example\":\n",
    "        return nanmean([stats.kendalltau(ref,pred).statistic for ref,pred in zip(refs,preds)]),\\\n",
    "                nanmean([stats.pearsonr(ref,pred).statistic for ref,pred in zip(refs,preds)]),\\\n",
    "                nanmean([stats.spearmanr(ref,pred).statistic for ref,pred in zip(refs,preds)])\n",
    "    else:\n",
    "        return stats.kendalltau(l_extend(refs),l_extend(preds)).statistic,\\\n",
    "            stats.pearsonr(l_extend(refs),l_extend(preds)).statistic,\\\n",
    "            stats.spearmanr(l_extend(refs),l_extend(preds)).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b22769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU\n",
      "\t java\n",
      "\t\t .337 .401\n",
      "\t cpp\n",
      "\t\t .146 .174\n",
      "\t python\n",
      "\t\t .251 .297\n",
      "\t js\n",
      "\t\t .168 .199\n",
      "\t average\n",
      "\t\t .225 .268\n",
      "CodeBLEU\n",
      "\t java\n",
      "\t\t .355 .421\n",
      "\t cpp\n",
      "\t\t .157 .187\n",
      "\t python\n",
      "\t\t .272 .323\n",
      "\t js\n",
      "\t\t .226 .267\n",
      "\t average\n",
      "\t\t .253 .299\n",
      "chrF\n",
      "\t java\n",
      "\t\t .346 .413\n",
      "\t cpp\n",
      "\t\t .166 .198\n",
      "\t python\n",
      "\t\t .262 .312\n",
      "\t js\n",
      "\t\t .186 .220\n",
      "\t average\n",
      "\t\t .240 .286\n",
      "ROUGE-L\n",
      "\t java\n",
      "\t\t .327 .389\n",
      "\t cpp\n",
      "\t\t .143 .171\n",
      "\t python\n",
      "\t\t .240 .284\n",
      "\t js\n",
      "\t\t .151 .179\n",
      "\t average\n",
      "\t\t .215 .256\n",
      "METEOR\n",
      "\t java\n",
      "\t\t .358 .425\n",
      "\t cpp\n",
      "\t\t .174 .208\n",
      "\t python\n",
      "\t\t .276 .327\n",
      "\t js\n",
      "\t\t .195 .231\n",
      "\t average\n",
      "\t\t .251 .298\n",
      "RUBY\n",
      "\t java\n",
      "\t\t .340 .401\n",
      "\t cpp\n",
      "\t\t .139 .165\n",
      "\t python\n",
      "\t\t .216 .255\n",
      "\t js\n",
      "\t\t .138 .163\n",
      "\t average\n",
      "\t\t .208 .246\n",
      "CodeBERTSCORE-F1 (w/o S.)\n",
      "\t java\n",
      "\t\t .333 .398\n",
      "\t cpp\n",
      "\t\t .146 .175\n",
      "\t python\n",
      "\t\t .237 .283\n",
      "\t js\n",
      "\t\t .148 .176\n",
      "\t average\n",
      "\t\t .216 .258\n",
      "CodeBERTSCORE-F1 (w/ S.)\n",
      "\t java\n",
      "\t\t .314 .375\n",
      "\t cpp\n",
      "\t\t .148 .177\n",
      "\t python\n",
      "\t\t .231 .276\n",
      "\t js\n",
      "\t\t .145 .172\n",
      "\t average\n",
      "\t\t .209 .250\n",
      "CodeBERTSCORE-F3 (w/o S.)\n",
      "\t java\n",
      "\t\t .359 .429\n",
      "\t cpp\n",
      "\t\t .169 .202\n",
      "\t python\n",
      "\t\t .265 .316\n",
      "\t js\n",
      "\t\t .180 .214\n",
      "\t average\n",
      "\t\t .243 .290\n",
      "CodeBERTSCORE-F3 (w/ S.)\n",
      "\t java\n",
      "\t\t .356 .426\n",
      "\t cpp\n",
      "\t\t .166 .198\n",
      "\t python\n",
      "\t\t .262 .312\n",
      "\t js\n",
      "\t\t .189 .226\n",
      "\t average\n",
      "\t\t .243 .291\n",
      "GPT-3.5 (w/o R.)\n",
      "\t java\n",
      "\t\t .427 .442\n",
      "\t cpp\n",
      "\t\t .320 .326\n",
      "\t python\n",
      "\t\t .279 .282\n",
      "\t js\n",
      "\t\t .316 .321\n",
      "\t average\n",
      "\t\t .336 .343\n",
      "GPT-3.5 (w/ R.)\n",
      "\t java\n",
      "\t\t .388 .404\n",
      "\t cpp\n",
      "\t\t .274 .282\n",
      "\t python\n",
      "\t\t .318 .325\n",
      "\t js\n",
      "\t\t .340 .348\n",
      "\t average\n",
      "\t\t .330 .340\n"
     ]
    }
   ],
   "source": [
    "# Example Level\n",
    "for m,rm in zip(exp_metrics,real_name_metrics):\n",
    "    print(rm)\n",
    "    kendalls,pearsons,spearmans=[],[],[]\n",
    "    for l in [\"java\",\"cpp\",\"python\",\"js\"]:\n",
    "        with open(f\"data/humaneval/humaneval_{l}_grade.json\") as f:\n",
    "            data = json.load(f)\n",
    "        kendall,pearson,spearman = compute(data,m,level=\"example\")\n",
    "        kendalls.append(kendall)\n",
    "        pearsons.append(pearson)\n",
    "        spearmans.append(spearman)\n",
    "        print(\"\\t\",l)\n",
    "        print(\"\\t\\t\",\n",
    "              \"{:.3f}\".format(round(kendall,3))[1:],\n",
    "              \"{:.3f}\".format(round(spearman,3))[1:])\n",
    "    print(\"\\t\",\"average\")\n",
    "    print(\"\\t\\t\",\n",
    "          \"{:.3f}\".format(round(mean(kendalls),3))[1:],\n",
    "          \"{:.3f}\".format(round(mean(spearmans),3))[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09454d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU\n",
      "\t java\n",
      "\t\t .267 .326\n",
      "\t cpp\n",
      "\t\t .225 .276\n",
      "\t python\n",
      "\t\t .281 .344\n",
      "\t js\n",
      "\t\t .220 .270\n",
      "\t average\n",
      "\t\t .248 .304\n",
      "CodeBLEU\n",
      "\t java\n",
      "\t\t .293 .359\n",
      "\t cpp\n",
      "\t\t .212 .260\n",
      "\t python\n",
      "\t\t .303 .371\n",
      "\t js\n",
      "\t\t .315 .385\n",
      "\t average\n",
      "\t\t .281 .343\n",
      "chrF\n",
      "\t java\n",
      "\t\t .290 .355\n",
      "\t cpp\n",
      "\t\t .266 .325\n",
      "\t python\n",
      "\t\t .328 .402\n",
      "\t js\n",
      "\t\t .279 .342\n",
      "\t average\n",
      "\t\t .291 .356\n",
      "ROUGE-L\n",
      "\t java\n",
      "\t\t .280 .342\n",
      "\t cpp\n",
      "\t\t .234 .286\n",
      "\t python\n",
      "\t\t .296 .363\n",
      "\t js\n",
      "\t\t .216 .264\n",
      "\t average\n",
      "\t\t .256 .314\n",
      "METEOR\n",
      "\t java\n",
      "\t\t .318 .389\n",
      "\t cpp\n",
      "\t\t .260 .319\n",
      "\t python\n",
      "\t\t .349 .427\n",
      "\t js\n",
      "\t\t .311 .380\n",
      "\t average\n",
      "\t\t .309 .379\n",
      "RUBY\n",
      "\t java\n",
      "\t\t .276 .337\n",
      "\t cpp\n",
      "\t\t .219 .268\n",
      "\t python\n",
      "\t\t .279 .341\n",
      "\t js\n",
      "\t\t .219 .268\n",
      "\t average\n",
      "\t\t .248 .303\n",
      "CodeBERTSCORE-F1 (w/o S.)\n",
      "\t java\n",
      "\t\t .299 .367\n",
      "\t cpp\n",
      "\t\t .266 .326\n",
      "\t python\n",
      "\t\t .322 .394\n",
      "\t js\n",
      "\t\t .248 .303\n",
      "\t average\n",
      "\t\t .284 .348\n",
      "CodeBERTSCORE-F1 (w/ S.)\n",
      "\t java\n",
      "\t\t .244 .298\n",
      "\t cpp\n",
      "\t\t .219 .268\n",
      "\t python\n",
      "\t\t .264 .324\n",
      "\t js\n",
      "\t\t .214 .262\n",
      "\t average\n",
      "\t\t .235 .288\n",
      "CodeBERTSCORE-F3 (w/o S.)\n",
      "\t java\n",
      "\t\t .326 .399\n",
      "\t cpp\n",
      "\t\t .283 .347\n",
      "\t python\n",
      "\t\t .360 .441\n",
      "\t js\n",
      "\t\t .296 .363\n",
      "\t average\n",
      "\t\t .316 .387\n",
      "CodeBERTSCORE-F3 (w/ S.)\n",
      "\t java\n",
      "\t\t .281 .344\n",
      "\t cpp\n",
      "\t\t .243 .297\n",
      "\t python\n",
      "\t\t .313 .384\n",
      "\t js\n",
      "\t\t .261 .320\n",
      "\t average\n",
      "\t\t .275 .336\n",
      "GPT-3.5 (w/o R.)\n",
      "\t java\n",
      "\t\t .330 .345\n",
      "\t cpp\n",
      "\t\t .313 .321\n",
      "\t python\n",
      "\t\t .294 .298\n",
      "\t js\n",
      "\t\t .315 .323\n",
      "\t average\n",
      "\t\t .313 .322\n",
      "GPT-3.5 (w/ R.)\n",
      "\t java\n",
      "\t\t .412 .438\n",
      "\t cpp\n",
      "\t\t .367 .383\n",
      "\t python\n",
      "\t\t .425 .446\n",
      "\t js\n",
      "\t\t .432 .455\n",
      "\t average\n",
      "\t\t .409 .431\n"
     ]
    }
   ],
   "source": [
    "# Corpus Level\n",
    "for m,rm in zip(exp_metrics,real_name_metrics):\n",
    "    print(rm)\n",
    "    kendalls,pearsons,spearmans=[],[],[]\n",
    "    for l in [\"java\",\"cpp\",\"python\",\"js\"]:\n",
    "        with open(f\"data/humaneval/humaneval_{l}_grade.json\") as f:\n",
    "            data = json.load(f)\n",
    "        kendall,pearson,spearman = compute(data,m,level=\"corpus\")\n",
    "        kendalls.append(kendall)\n",
    "        pearsons.append(pearson)\n",
    "        spearmans.append(spearman)\n",
    "        print(\"\\t\",l)\n",
    "        print(\"\\t\\t\",\n",
    "              \"{:.3f}\".format(round(kendall,3))[1:],\n",
    "              \"{:.3f}\".format(round(spearman,3))[1:])\n",
    "    print(\"\\t\",\"average\")\n",
    "    print(\"\\t\\t\",\n",
    "          \"{:.3f}\".format(round(mean(kendalls),3))[1:],\n",
    "          \"{:.3f}\".format(round(mean(spearmans),3))[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
